package com.bodhi.arithmetictestdemo.practice;

/**
 * @author : Sun
 * @version : 1.0
 * create time : 2019/7/23 23:55
 * desc :认识一致性哈希
 *
 * 一致性哈希：假如有2^64次方的空间(环形) 分别有m1,m2,m3三台机器通过hash函数(此时不再取模运算)
 * 算出具体位置，则整个2^64空间是由m1,m2,m3三个节点构成的一个环，则m1~m2上的数据由m2负责，m2~
 * m3上的数据由m3负责，m3~m1上的数据由m1负责。此时如果突然加入一台服务器m4 通过hash函数算出来
 * 具体位置在m2和m3之间，则此时相当于整个2^64空间是由m1,m2,m3,m4四个节点构成的一个环，并且m1~
 * m2,m2~m4,m4~m3,m3~m1分成四段，原先m1~m2，m3~m1上的数据还是分别由m2,m1负责数据不用变，只
 * 是相当于把原先m2~m3上数据的一部分由原先m3负责迁移到m4上，减机器同理，所以数据迁移代价很低，但
 * 是在机器很少的情况下 很难发挥哈希函数的特性(在大数据量的前提下数据基本是均匀分布的)，所以m1,m2,
 * m3所分成的区间不一定均等 导致每个机器负责的数据可能有的特别多有的特别少，为了解决负载均衡问题引
 * 入了虚拟节点技术 在本地构建一张对应表 分别给m1,m2,m3分配1000个子节点 即m1-1,m1-2...m1-1000
 * 然后让m1,m2,m3各自的1000个子节点通过hash函数算出具体位置分布在整个环上 此时整个2^64空间由3000
 * 个子节点均匀分布（此时数据量够大），然后对应的子节点区域由父节点负责 这样m1,m2,m3负责的数据基本
 * 均衡一样多，此时在加入个新的机器m4，同样给m4分配1000个子节点 通过hash函数分布到环上，这就达到
 * 了数据总体迁移量变小 同时每个机器负责的数据几乎也一样多
 *
 *
 * 应用场景：把数据迁移的代价控制的很低 同时又负载均衡
 * 因为在经典哈希函数中 哈希函数计算结果取模时的开辟空间大小变化后 要重新计算所有数据的哈希返回值
 *
 * 引入的技术：虚拟节点技术 解决负载均衡问题
 *
 */
public class HashPractice_SameHash {


}
